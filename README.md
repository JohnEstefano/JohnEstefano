<h1> Hey there! I'm John. <img src="https://github.com/JohnEstefano/JohnEstefano/blob/main/Hi.gif" width="25"></h1>
<img align="right" alt="GIF" src="https://github.com/JohnEstefano/JohnEstefano/blob/main/gif3.gif" width="500"/>

<h3> ğŸ‘¨ğŸ»â€ğŸ’» About Me </h3>

- ğŸ’¼ &nbsp; I work as a data engineer at a digital marketing agency called MediaCom (GroupM Subsidiary)
- ğŸ”­ &nbsp; Iâ€™m always working on adding and polishing my data enigeering toolkit
- ğŸ¤” &nbsp; I love exploring new technologies and developing software solutions and quick hacks.
- ğŸŒ± &nbsp; Enthusiast in all things tech and data enginering.
- âœï¸ &nbsp; Aside from coding I enjoy playing video games, watching cooking shows on youtube and trying out anything that piques my interest.
- â˜• &nbsp; I belive, a perfect cup of chamomile tea can be the ultimate solution for any stress. 
- ğŸ˜„ Pronouns: he/him/his

<h3>ğŸ›  Tech Stack</h3>

- ğŸ’» &nbsp; Main Languages: Python | SQL 
- ğŸ–¥ &nbsp; System Environments: macOS | Windows | macOS 
- ğŸŒ &nbsp; Cloud Platforms: Amazon Web Services | Google Cloud Platform | IBM Cloud
- ğŸ›¢ &nbsp; Databases: MySQL | PostgreSQL | Cassandra | Redshift
- ğŸ”§ &nbsp; Big Data Tools: Hadoop | Sqoop | Kafka | Faust | Avro | Spark | Airflow | Spark Streams | KSQL | EMR | Hudi | EC2 | S3 | REST Proxy

<h3>ğŸ›  Data Engineering Projects</h3>
<h4> PROJECT SPARKIFY: Below is project that showcase my iterative data engineering skills. Each step increases the robustness of the data pipeline by adding an extra layer of functionally.</h4>

A startup called Sparkify wanted to analyze the data they've been collecting on songs and user activity on their new music streaming app. The analytics team was particularly interested in understanding what songs users are listening to. 

[Step 1](https://github.com/JohnEstefano/POSTGRES_Data_Modeling): Their data resided in a directory of JSON logs on user activity on the app, as well as a directory with JSON metadata on the songs in their app. So, I created Postgres database with tables designed to optimize queries on song play analysis. Along with a database schema and ETL pipeline for this analysis.

[Step 2](https://github.com/JohnEstefano/APACHE_CASSANDRA_Data_Modeling):  Their data resided in a directory of CSV files and they wanted the solution to have scalability and high availability with compromising performance. So, I created an Apache Cassandra database.

[Step 3](https://github.com/JohnEstefano/AWS_Data_Warehouse): Sparkify, has grown their user base and song database and wants to move their processes and data onto the cloud. Their data resides in S3, in a directory of JSON logs on user activity on the app, as well as a directory with JSON metadata on the songs in their app. So, I built an ETL pipeline that extracts their data from S3, stages them in Redshift, and transforms data into a set of dimensional tables for their analytics team to continue finding insights.

[Step 4](https://github.com/JohnEstefano/AWS_Data_Lake): Adds Apache Spark to increase the pipelineâ€™s data processing ability so it can handle large scale data processing.

[Step 5](https://github.com/JohnEstefano/AIRFLOW_Data_Pipeline): Adds Apache Airflow in the mix to introduce more automation and monitoring to their data warehouse ETL pipelines.

<br>

<img align="center" src="https://github-readme-stats.vercel.app/api?username=johnestefano&include_all_commits=true&count_private=true&show_icons=true&line_height=20&title_color=7A7ADB&icon_color=2234AE&text_color=D3D3D3&bg_color=0,000000,130F40" alt="johnestefano's Github Stats">

</br>

<h3> ğŸ¤ğŸ» Connect with Me </h3>

<p align="center">
&nbsp; <a href="https://www.linkedin.com/in/johnestefanoortiz/" target="_blank" rel="noopener noreferrer"><img src="https://img.icons8.com/plasticine/100/000000/linkedin.png" width="50" /></a>
&nbsp; <a href="mailto:johnestefano14@gmail.com" target="_blank" rel="noopener noreferrer"><img src="https://img.icons8.com/plasticine/100/000000/gmail.png"  width="50" /></a>
</p>

â­ï¸ From [John Estefano](https://github.com/JohnEstefano)
